# Motor City Math â€” Marcus Queue

> Items needing Marcus's input or decisions. Agents write here, Marcus reads and responds.
> Severity: ðŸ”´ BLOCKER (can't proceed) Â· ðŸŸ¡ DECISION (need a choice) Â· ðŸŸ¢ FYI (informational)

---

## Status Summary

**Last updated:** 2026-02-17
**Project:** 12 HTML practice tests, ~200 questions, ~14,700 LOC
**Agents:** 6 registered, 1 active (Design), 5 awaiting onboarding

---

## Open Items

### ðŸ”´ BLOCKER â€” Agent R: 21 math errors found in answer keys/grading
**Filed:** 2026-02-17 by Research Agent

Marcus, the math audit is complete. **8 of 12 files are clean.** But 4 files have significant errors:

**`index.html` â€” Grading is 100% broken.** The auto-grading JavaScript was copy-pasted from `index_calc.html` and doesn't match index.html's questions at all. Every auto-graded answer would be wrong, and the function crashes on Q11/Q14 (elements don't exist). The answer key MODAL is mostly correct â€” Kai likely used that, not auto-grading. **This is why he still got an A.**

**`final_exam_251123.html` â€” 6 wrong headline answers.** The work steps are correct but the bolded answer numbers are wrong (Q1: -234â†’210, Q5: -3â†’-9, Q6: sign error, Q7: 12/13â†’6/5, Q16b: off by one period, Q17b: computation error). If Kai reads the work, he gets the right answer. If he just reads the bold number, he learns the wrong thing.

**`index_calc.html` â€” 2 computation errors.** Q6d (62â†’66Â°F) and Q16b ($14,636.56â†’$14,616.18).

**Decision needed:** Should Agent A fix these now (before any other work), or should we prioritize the shared CSS/JS extraction first? My recommendation: fix the answer keys first â€” they're surgical changes (just number replacements) and directly affect Kai's learning.

Full bug list with correct answers is in `.agent-status.md` â†’ Bugs section.

---

## Resolved Items

<details>
<summary>Click to expand resolved items</summary>

_(none yet)_

</details>
